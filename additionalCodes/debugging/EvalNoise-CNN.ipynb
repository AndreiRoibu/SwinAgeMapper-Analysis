{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qlogin -q short.qg -l gpu=1[affinity=true],gputype=rtx8000\n",
    "# # qlogin -q short.qg -l gpu=1[affinity=true],gputype=a100\n",
    "\n",
    "# srun -p gpu_short --gres gpu:1 --constraint='a100-pcie-80gb|quadro-rtx8000|a100-pcie-40gb' --pty bash\n",
    "srun -p gpu_short --gres gpu:1 --constraint='a100-pcie-80gb' --pty bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "cd /well/win/users/hsv459/agemapper\n",
    "\n",
    "module purge\n",
    "module load Python/3.7.4-GCCcore-8.3.0\n",
    "\n",
    "source /well/win-fmrib-analysis/users/hsv459/python/swinagemapper-skylake/bin/activate\n",
    "echo \"Loaded swinagemapper-skylake environment.\"\n",
    "\n",
    "# continue to use your python venv as normal\n",
    "   \n",
    "ipython\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "from solver import Solver\n",
    "from utils.data_utils import get_datasets_dynamically, get_test_datasets_dynamically\n",
    "from utils.settings import Settings\n",
    "import utils.data_evaluation as evaluations\n",
    "from utils.misc import create_folder\n",
    "\n",
    "from AgeMapper import AgeMapper\n",
    "\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "MSELoss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9557ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "networks=[\n",
    "    'AC3-1',\n",
    "    'AC2-6',\n",
    "    'AC3-3',\n",
    "    'AC1-5',\n",
    "    'AC5-7',\n",
    "    'AC6-8',\n",
    "    'AC6-16',\n",
    "]\n",
    "\n",
    "\n",
    "noiseSTD = [\n",
    "    0,0.01,0.02,0.04,0.06,0.08,\n",
    "    0.1,0.12,0.14,0.16,0.18,0.2\n",
    "]\n",
    "\n",
    "def load_data_dynamically(data_parameters, mapping_evaluation_parameters=None, flag='train'):\n",
    "    \n",
    "    if flag=='train':\n",
    "        print(\"Data is loading...\")\n",
    "        train_data, validation_data, resolution = get_datasets_dynamically(data_parameters)\n",
    "        print(\"Data has loaded!\")\n",
    "        print(\"Training dataset size is {}\".format(len(train_data)))\n",
    "        print(\"Validation dataset size is {}\".format(len(validation_data)))\n",
    "        return train_data, validation_data, resolution\n",
    "    elif flag=='test':\n",
    "        print(\"Data is loading...\")\n",
    "        test_data, volumes_to_be_used, prediction_output_statistics_name, resolution = get_test_datasets_dynamically(data_parameters, mapping_evaluation_parameters)\n",
    "        print(\"Data has loaded!\")\n",
    "        len_test_data = len(test_data)\n",
    "        print(\"Testing dataset size is {}\".format(len_test_data))\n",
    "        return test_data, volumes_to_be_used, prediction_output_statistics_name, len_test_data, resolution\n",
    "    else:\n",
    "        print('ERROR: Invalid Flag')\n",
    "        return None\n",
    "    \n",
    "def _load_mean(dataset_sex):\n",
    "\n",
    "    if dataset_sex == 'male':\n",
    "        mean_age = 64.64810970818492\n",
    "    else:\n",
    "        mean_age = 63.370316719492536\n",
    "\n",
    "    mean_age = np.array(np.float32(mean_age))\n",
    "\n",
    "    return mean_age \n",
    "\n",
    "def _statistics_calculator(output_age, target_age):\n",
    "\n",
    "    output_age = np.array(output_age)\n",
    "    target_age = np.array(target_age)\n",
    "    age_delta = output_age - target_age\n",
    "    loss = MSELoss(torch.from_numpy(output_age), torch.from_numpy(target_age)).numpy()\n",
    "\n",
    "    return age_delta, loss\n",
    "\n",
    "\n",
    "for idx in range(len(networks)):\n",
    "    \n",
    "    \n",
    "    # Find the pretrained network weights\n",
    "    \n",
    "    network = networks[idx]\n",
    "    \n",
    "    print('NETWORK: {}'.format(network))\n",
    "\n",
    "    network_path = '/well/win-fmrib-analysis/users/hsv459/agemapper/saved_models/'\n",
    "    network_name = network + '.pth.tar'\n",
    "    network_path += network_name\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    trained_model = torch.load(network_path, map_location=torch.device(device))\n",
    "\n",
    "    \n",
    "    # Load the settings\n",
    "    \n",
    "    settings_file_name = network + '.ini'\n",
    "    evaluation_settings_file_name = network + '_eval.ini'\n",
    "    settings = Settings(settings_file_name)\n",
    "    settings_evaluation = Settings(evaluation_settings_file_name)\n",
    "\n",
    "    mapping_evaluation_parameters = settings_evaluation['MAPPING']\n",
    "    data_parameters = settings['DATA']\n",
    "    training_parameters = settings['TRAINING']\n",
    "    network_parameters = settings['NETWORK']\n",
    "    misc_parameters = settings['MISC']\n",
    "    \n",
    "    # Get the pretrained model resolution\n",
    "    \n",
    "    data_directory = data_parameters['data_directory']\n",
    "    modality_flag = data_parameters['modality_flag']\n",
    "    scaling_values_simple = pd.read_csv(data_parameters['scaling_values'], index_col=0)\n",
    "    resolution = scaling_values_simple.loc[modality_flag].resolution\n",
    "    del scaling_values_simple\n",
    "\n",
    "    # Get the pretrained model ready\n",
    "\n",
    "    dropout_rate_1 = network_parameters['dropout_rate_1']\n",
    "    dropout_rate_2 = network_parameters['dropout_rate_2']\n",
    "    dropout_rate_3 = network_parameters['dropout_rate_3']\n",
    "\n",
    "    model = AgeMapper(resolution=resolution,\n",
    "                                    dropout_rate_1=dropout_rate_1,\n",
    "                                    dropout_rate_2=dropout_rate_2,\n",
    "                                    dropout_rate_3=dropout_rate_3,\n",
    "                                    )\n",
    "\n",
    "    model.load_state_dict(trained_model)\n",
    "\n",
    "    del trained_model, network_path, network_name\n",
    "\n",
    "    if torch.cuda.is_available() == True and device!='cpu':\n",
    "        model.cuda(device)\n",
    "\n",
    "    model.eval();\n",
    "    \n",
    "    \n",
    "    # Prepare the output folder and several other settings\n",
    "    \n",
    "    mapping_evaluation_parameters['experiment_name'] = mapping_evaluation_parameters['experiment_name'] + '_noise'\n",
    "    experiment_name = mapping_evaluation_parameters['experiment_name']\n",
    "    prediction_output_path = experiment_name + \"_predictions\"\n",
    "    create_folder(prediction_output_path)\n",
    "    \n",
    "    \n",
    "    trained_model_path = \"saved_models/\" + experiment_name + \".pth.tar\"\n",
    "    control = mapping_evaluation_parameters['control']\n",
    "    dataset_sex = data_parameters['dataset_sex']\n",
    "    \n",
    "    data_parameters['noise_mean'] = 0.\n",
    "    \n",
    "    \n",
    "    # Start a loop going through the various noise settings\n",
    "    \n",
    "    for std in noiseSTD:\n",
    "        \n",
    "        print('----> std=',std)\n",
    "        \n",
    "        data_parameters['noise_std'] = std\n",
    "        \n",
    "        test_data, volumes_to_be_used, prediction_output_statistics_name, len_test_data, resolution = load_data_dynamically(\n",
    "                                                data_parameters=data_parameters, \n",
    "                                                mapping_evaluation_parameters=mapping_evaluation_parameters, \n",
    "                                                flag='test'\n",
    "                                                )\n",
    "        \n",
    "        test_loader = data.DataLoader(\n",
    "            dataset = test_data,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=data_parameters['num_workers']\n",
    "        )\n",
    "\n",
    "        output_statistics = {}\n",
    "        output_statistics_path = os.path.join(prediction_output_path, prediction_output_statistics_name + '_' + str(std))\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch_index, sampled_batch in enumerate(test_loader):\n",
    "                X = sampled_batch[0].type(torch.FloatTensor)\n",
    "                y_age = sampled_batch[1].type(torch.FloatTensor)\n",
    "                y_age = (y_age.cpu().numpy()).astype('float32')\n",
    "                y_age = np.squeeze(y_age)\n",
    "                subject = volumes_to_be_used[batch_index]\n",
    "\n",
    "                # We add an extra dimension (~ number of channels) for the 3D convolutions.\n",
    "                if len(X.size())<5:\n",
    "                    X = torch.unsqueeze(X, dim=1)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    X = X.cuda(device, non_blocking=True)\n",
    "\n",
    "                y_hat = model(X)   # Forward pass\n",
    "                y_hat = (y_hat.cpu().numpy()).astype('float32')\n",
    "                y_hat = np.squeeze(y_hat)\n",
    "\n",
    "                target_age = y_age\n",
    "\n",
    "                age_delta, loss = _statistics_calculator(y_hat, target_age)\n",
    "                output_statistics[subject] = [target_age, y_hat, age_delta, loss]\n",
    "\n",
    "                print(\"\\r Processed {:.3f}%: {}/{} subjects\".format((batch_index+1)/len_test_data * 100.0, batch_index+1, len_test_data), end='')\n",
    "\n",
    "            output_statistics_df = pd.DataFrame.from_dict(output_statistics, orient='index', columns=['target_age', 'output_age', 'age_delta', 'loss'])     \n",
    "            output_statistics_df.to_csv(output_statistics_path)\n",
    "\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_dynamically(data_parameters, mapping_evaluation_parameters=None, flag='train'):\n",
    "    \n",
    "    if flag=='train':\n",
    "        print(\"Data is loading...\")\n",
    "        train_data, validation_data, resolution = get_datasets_dynamically(data_parameters)\n",
    "        print(\"Data has loaded!\")\n",
    "        print(\"Training dataset size is {}\".format(len(train_data)))\n",
    "        print(\"Validation dataset size is {}\".format(len(validation_data)))\n",
    "        return train_data, validation_data, resolution\n",
    "    elif flag=='test':\n",
    "        print(\"Data is loading...\")\n",
    "        test_data, volumes_to_be_used, prediction_output_statistics_name, resolution = get_test_datasets_dynamically(data_parameters, mapping_evaluation_parameters)\n",
    "        print(\"Data has loaded!\")\n",
    "        len_test_data = len(test_data)\n",
    "        print(\"Testing dataset size is {}\".format(len_test_data))\n",
    "        return test_data, volumes_to_be_used, prediction_output_statistics_name, len_test_data, resolution\n",
    "    else:\n",
    "        print('ERROR: Invalid Flag')\n",
    "        return None\n",
    "    \n",
    "def _load_mean(dataset_sex):\n",
    "\n",
    "    if dataset_sex == 'male':\n",
    "        mean_age = 64.64810970818492\n",
    "    else:\n",
    "        mean_age = 63.370316719492536\n",
    "\n",
    "    mean_age = np.array(np.float32(mean_age))\n",
    "\n",
    "    return mean_age \n",
    "\n",
    "def _statistics_calculator(output_age, target_age):\n",
    "\n",
    "    output_age = np.array(output_age)\n",
    "    target_age = np.array(target_age)\n",
    "    age_delta = output_age - target_age\n",
    "    loss = MSELoss(torch.from_numpy(output_age), torch.from_numpy(target_age)).numpy()\n",
    "\n",
    "    return age_delta, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1adb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx in range(len(networks)):\n",
    "    \n",
    "    \n",
    "    # Find the pretrained network weights\n",
    "    \n",
    "    network = networks[idx]\n",
    "    \n",
    "    print('NETWORK: {}'.format(network))\n",
    "\n",
    "    network_path = '/well/win-fmrib-analysis/users/hsv459/agemapper/saved_models/'\n",
    "    network_name = network + '.pth.tar'\n",
    "    network_path += network_name\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    trained_model = torch.load(network_path, map_location=torch.device(device))\n",
    "\n",
    "    \n",
    "    # Load the settings\n",
    "    \n",
    "    settings_file_name = network + '.ini'\n",
    "    evaluation_settings_file_name = network + '_eval.ini'\n",
    "    settings = Settings(settings_file_name)\n",
    "    settings_evaluation = Settings(evaluation_settings_file_name)\n",
    "\n",
    "    mapping_evaluation_parameters = settings_evaluation['MAPPING']\n",
    "    data_parameters = settings['DATA']\n",
    "    training_parameters = settings['TRAINING']\n",
    "    network_parameters = settings['NETWORK']\n",
    "    misc_parameters = settings['MISC']\n",
    "    \n",
    "    # Get the pretrained model resolution\n",
    "    \n",
    "    data_directory = data_parameters['data_directory']\n",
    "    modality_flag = data_parameters['modality_flag']\n",
    "    scaling_values_simple = pd.read_csv(data_parameters['scaling_values'], index_col=0)\n",
    "    resolution = scaling_values_simple.loc[modality_flag].resolution\n",
    "    del scaling_values_simple\n",
    "\n",
    "    # Get the pretrained model ready\n",
    "\n",
    "    dropout_rate_1 = network_parameters['dropout_rate_1']\n",
    "    dropout_rate_2 = network_parameters['dropout_rate_2']\n",
    "    dropout_rate_3 = network_parameters['dropout_rate_3']\n",
    "\n",
    "    model = AgeMapper(resolution=resolution,\n",
    "                                    dropout_rate_1=dropout_rate_1,\n",
    "                                    dropout_rate_2=dropout_rate_2,\n",
    "                                    dropout_rate_3=dropout_rate_3,\n",
    "                                    )\n",
    "\n",
    "    model.load_state_dict(trained_model)\n",
    "\n",
    "    del trained_model, network_path, network_name\n",
    "\n",
    "    if torch.cuda.is_available() == True and device!='cpu':\n",
    "        model.cuda(device)\n",
    "\n",
    "    model.eval();\n",
    "    \n",
    "    \n",
    "    # Prepare the output folder and several other settings\n",
    "    \n",
    "    mapping_evaluation_parameters['experiment_name'] = mapping_evaluation_parameters['experiment_name'] + '_noise'\n",
    "    experiment_name = mapping_evaluation_parameters['experiment_name']\n",
    "    prediction_output_path = experiment_name + \"_predictions\"\n",
    "    create_folder(prediction_output_path)\n",
    "    \n",
    "    \n",
    "    trained_model_path = \"saved_models/\" + experiment_name + \".pth.tar\"\n",
    "    control = mapping_evaluation_parameters['control']\n",
    "    dataset_sex = data_parameters['dataset_sex']\n",
    "    \n",
    "    data_parameters['noise_mean'] = 0.\n",
    "    \n",
    "    \n",
    "    # Start a loop going through the various noise settings\n",
    "    \n",
    "    for std in noiseSTD:\n",
    "        \n",
    "        print('----> std=',std)\n",
    "        \n",
    "        data_parameters['noise_std'] = std\n",
    "        \n",
    "        test_data, volumes_to_be_used, prediction_output_statistics_name, len_test_data, resolution = load_data_dynamically(\n",
    "                                                data_parameters=data_parameters, \n",
    "                                                mapping_evaluation_parameters=mapping_evaluation_parameters, \n",
    "                                                flag='test'\n",
    "                                                )\n",
    "        \n",
    "        test_loader = data.DataLoader(\n",
    "            dataset = test_data,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=data_parameters['num_workers']\n",
    "        )\n",
    "\n",
    "        output_statistics = {}\n",
    "        output_statistics_path = os.path.join(prediction_output_path, prediction_output_statistics_name + '_' + str(std))\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch_index, sampled_batch in enumerate(test_loader):\n",
    "                X = sampled_batch[0].type(torch.FloatTensor)\n",
    "                y_age = sampled_batch[1].type(torch.FloatTensor)\n",
    "                y_age = (y_age.cpu().numpy()).astype('float32')\n",
    "                y_age = np.squeeze(y_age)\n",
    "                subject = volumes_to_be_used[batch_index]\n",
    "\n",
    "                # We add an extra dimension (~ number of channels) for the 3D convolutions.\n",
    "                if len(X.size())<5:\n",
    "                    X = torch.unsqueeze(X, dim=1)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    X = X.cuda(device, non_blocking=True)\n",
    "\n",
    "                y_hat = model(X)   # Forward pass\n",
    "                y_hat = (y_hat.cpu().numpy()).astype('float32')\n",
    "                y_hat = np.squeeze(y_hat)\n",
    "\n",
    "                target_age = y_age\n",
    "\n",
    "                age_delta, loss = _statistics_calculator(y_hat, target_age)\n",
    "                output_statistics[subject] = [target_age, y_hat, age_delta, loss]\n",
    "\n",
    "                print(\"\\r Processed {:.3f}%: {}/{} subjects\".format((batch_index+1)/len_test_data * 100.0, batch_index+1, len_test_data), end='')\n",
    "\n",
    "            output_statistics_df = pd.DataFrame.from_dict(output_statistics, orient='index', columns=['target_age', 'output_age', 'age_delta', 'loss'])     \n",
    "            output_statistics_df.to_csv(output_statistics_path)\n",
    "\n",
    "        print('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
